# src/eval.py
import argparse
import os
from pathlib import Path
import csv
import numpy as np
from tqdm import tqdm
from skimage.metrics import peak_signal_noise_ratio, structural_similarity

from src.utils.io import load_rgb, save_rgb
from src.utils.tiling import tiled_process
from src.utils.postprocess import postprocess

from src.models.dehazeformer_wrapper import DehazeFormerWrapper
from src.models.wavelet_unet_wrapper import WaveletUNetWrapper


VALID_EXTS = {".png", ".jpg", ".jpeg", ".bmp", ".tif", ".tiff"}


def list_images(folder: Path):
    files = [p for p in folder.iterdir() if p.suffix.lower() in VALID_EXTS]
    files.sort()
    return files


def run_with_fallback_tiles(img, fn_tile, overlap: int, tiles):
    import torch
    last_err = None
    for t in tiles:
        try:
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            return tiled_process(img, fn_tile=fn_tile, tile=t, overlap=overlap)
        except RuntimeError as e:
            msg = str(e).lower()
            if "out of memory" in msg:
                last_err = e
                continue
            raise
    raise RuntimeError(f"All tile sizes failed due to OOM. Last error: {last_err}")


def compute_metrics(pred_u8: np.ndarray, gt_u8: np.ndarray):
    # PSNR expects float in [0,255] or [0,1]; we use [0,255]
    psnr = peak_signal_noise_ratio(gt_u8, pred_u8, data_range=255)

    # SSIM over color image
    ssim = structural_similarity(
        gt_u8, pred_u8,
        channel_axis=2,
        data_range=255
    )
    return float(psnr), float(ssim)


def main():
    ap = argparse.ArgumentParser()

    ap.add_argument("--hazy_dir", required=True, help="Folder of hazy images")
    ap.add_argument("--gt_dir", required=True, help="Folder of GT/clear images (same filenames)")
    ap.add_argument("--out_dir", default="outputs_eval", help="Where to save predicted images")
    ap.add_argument("--csv", default="metrics.csv", help="CSV filename inside out_dir")

    ap.add_argument("--model", required=True, choices=["dehazeformer", "wavelet-unet"])
    ap.add_argument("--ckpt", required=True, help="Checkpoint path for selected model (.pth)")
    ap.add_argument("--device", default="cuda")

    # DehazeFormer-specific
    ap.add_argument("--variant", default="t", choices=["t", "s", "b"])

    # Inference controls
    ap.add_argument("--tiles", default="640,512,384,320")
    ap.add_argument("--overlap", type=int, default=96)

    # Optional postprocessing
    ap.add_argument("--post", action="store_true")
    ap.add_argument("--wb_strength", type=float, default=0.6)
    ap.add_argument("--gamma", type=float, default=0.95)
    ap.add_argument("--clahe_strength", type=float, default=0.25)

    args = ap.parse_args()

    hazy_dir = Path(args.hazy_dir)
    gt_dir = Path(args.gt_dir)
    out_dir = Path(args.out_dir)
    out_dir.mkdir(parents=True, exist_ok=True)

    tiles = [int(x.strip()) for x in args.tiles.split(",") if x.strip()]

    # Load model
    if args.model == "dehazeformer":
        model = DehazeFormerWrapper(variant=args.variant, ckpt_path=args.ckpt).load(device=args.device)
    else:
        model = WaveletUNetWrapper(ckpt_path=args.ckpt).load(device=args.device)

    hazy_files = list_images(hazy_dir)
    if len(hazy_files) == 0:
        raise RuntimeError(f"No images found in hazy_dir: {hazy_dir}")

    rows = []
    psnrs, ssims = [], []

    for hp in tqdm(hazy_files, desc=f"Evaluating {args.model}"):
        gp = gt_dir / hp.name
        if not gp.exists():
            # skip if no matching GT
            continue

        hazy = load_rgb(str(hp))
        gt = load_rgb(str(gp))

        def fn(tile_img):
            return model.predict_tile(tile_img)

        pred = run_with_fallback_tiles(hazy, fn_tile=fn, overlap=args.overlap, tiles=tiles)

        if args.post:
            pred = postprocess(
                pred,
                wb_strength=float(args.wb_strength),
                gamma=float(args.gamma),
                clahe_strength=float(args.clahe_strength),
            )

        psnr, ssim = compute_metrics(pred, gt)
        psnrs.append(psnr)
        ssims.append(ssim)

        save_rgb(str(out_dir / hp.name), pred)

        rows.append({
            "file": hp.name,
            "psnr": psnr,
            "ssim": ssim
        })

    # Summary
    mean_psnr = float(np.mean(psnrs)) if psnrs else float("nan")
    mean_ssim = float(np.mean(ssims)) if ssims else float("nan")

    # Write CSV
    csv_path = out_dir / args.csv
    with open(csv_path, "w", newline="") as f:
        w = csv.DictWriter(f, fieldnames=["file", "psnr", "ssim"])
        w.writeheader()
        for r in rows:
            w.writerow(r)
        w.writerow({"file": "__MEAN__", "psnr": mean_psnr, "ssim": mean_ssim})

    print(f"Saved predictions to: {out_dir}")
    print(f"Saved metrics CSV to: {csv_path}")
    print(f"MEAN  PSNR={mean_psnr:.4f}  SSIM={mean_ssim:.4f}")


if __name__ == "__main__":
    main()